{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import param\n",
    "import numpy\n",
    "from numpy import array\n",
    "\n",
    "from scipy.ndimage import measurements\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "from skimage.morphology import reconstruction\n",
    "\n",
    "import holoviews as hv\n",
    "colormaps = hv.plotting.list_cmaps()\n",
    "\n",
    "import hvplot.xarray\n",
    "from holoviews.selection import link_selections\n",
    "from holoviews.element.selection import spatial_select\n",
    "from holoviews import opts\n",
    "\n",
    "opts.defaults(\n",
    "    opts.Image(\n",
    "        # Values taken from holoviews.Store.custom_options for a xarray.Dataset.hvplot()\n",
    "        colorbar=True,\n",
    "        logx=False,\n",
    "        logy=False,\n",
    "        responsive=True,\n",
    "        aspect=2,\n",
    "        shared_axes=True,\n",
    "        show_grid=False,\n",
    "        show_legend=True,\n",
    "        tools=['hover','lasso_select', 'box_select'], # Default = hover \n",
    "    )\n",
    ")\n",
    "\n",
    "import panel as pn\n",
    "pn.config.sizing_mode = 'stretch_width'\n",
    "\n",
    "from bokeh.models import FixedTicker\n",
    "\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueChanger(param.Parameterized):\n",
    "    \n",
    "    # How we are going to modify the values\n",
    "    # Absolute => Set to that value\n",
    "    # Relative => Base value + new value\n",
    "    # Percentage => Base value + percentage\n",
    "    calculation_type = pn.widgets.RadioButtonGroup(options=['Absolute', 'Relative', 'Percentage'], align='end')\n",
    "    # Replacement value\n",
    "    # spinner = pn.widgets.IntInput(name='Replacement Value', value=0, align='start')\n",
    "    spinner = pn.widgets.FloatInput(name='Replacement Value', value=0., step=1e-3, align='start') # start=0, end=1000\n",
    "\n",
    "    # Buttons\n",
    "    download_netcdf = pn.widgets.FileDownload(label='\\u21A7  Download NetCDF', button_type='success')\n",
    "    download_script = pn.widgets.FileDownload(label='\\u21A7  Download as .py', button_type='success', filename='modify_netcdf.py')\n",
    "    apply = pn.widgets.Button(name='\\u2713 Apply', align='end', button_type='primary')\n",
    "    undo_button = pn.widgets.Button(name='\\u21B6 Undo', align='end', button_type='warning')\n",
    "    redo_button = pn.widgets.Button(name='Redo \\u21B7', align='end', button_type='warning')\n",
    "    fill_depressions_button = pn.widgets.Button(name='Fill Depressions', button_type='primary')\n",
    "    # Mask\n",
    "    mask = pn.widgets.Checkbox(name='Mask', max_width=100)\n",
    "    mask_value = pn.widgets.IntInput(name='Mask Value', value=0)\n",
    "    # Show extra graphs\n",
    "    show_internal_oceans = pn.widgets.Checkbox(value=True, name='Show Internal Oceans', align='start')\n",
    "    show_passage_problems = pn.widgets.Checkbox(value=True, name='Show Diffusion Passages ', align='start')\n",
    "    # Store the variable we want to look at and modify\n",
    "    attribute = pn.widgets.Select(name='Variable', max_width=200, align='end')\n",
    "    # Load the file from disk\n",
    "    file = param.Parameter()\n",
    "    # Choose colormap\n",
    "    colormap = pn.widgets.Select(name='Colormap', options=colormaps, value='terrain', max_width=200, align='start')\n",
    "    colormap_min = pn.widgets.IntInput(name='Min Value', width=100)\n",
    "    colormap_max = pn.widgets.IntInput(name='Max Value', width=100, align='end')\n",
    "    colormap_range_slider = pn.widgets.RangeSlider(width=400, show_value=False)\n",
    "    colormap_delta = pn.widgets.IntInput(name='Delta between values', value=0, align='end')\n",
    "    # Holoviews.DataSet => Data\n",
    "    ds = param.Parameter()\n",
    "    # Link the viewing of multiple graphs together\n",
    "    selection = link_selections.instance(unselected_alpha=0.4)\n",
    "    \n",
    "    # Used to store when inital data is loaded\n",
    "    loaded = param.Parameter()\n",
    "    \n",
    "    # Parts of the display\n",
    "    file_pane = pn.Column()\n",
    "    graph_pane = pn.Column()\n",
    "    options_pane = pn.Column()\n",
    "    \n",
    "    def __init__(self, **params):\n",
    "        self.param.file.default = pn.widgets.FileInput(max_width=200)\n",
    "        self.param.ds.default = xr.Dataset()\n",
    "        self.param.loaded.default = False\n",
    "        super().__init__(**params)\n",
    "        self.apply.on_click(self._apply_values)\n",
    "        self.undo_button.on_click(self.undo)\n",
    "        self.redo_button.on_click(self.redo)\n",
    "        self.download_netcdf.callback = self._download_netcdf\n",
    "        self.download_script.callback = self._download_script\n",
    "        self.fill_depressions_button.on_click(self._fill_depressions_callback)\n",
    "        self.file_pane.append(self.file)\n",
    "        self._auto_update_cmap_min = True\n",
    "        self._auto_update_cmap_max = True\n",
    "        \n",
    "        self.curvilinear_coordinates = None\n",
    "        self._undo_list = []\n",
    "        self._redo_list = []\n",
    "        \n",
    "        self.colormap_min.param.watch(self._colormap_callback, 'value')\n",
    "        self.colormap_max.param.watch(self._colormap_callback, 'value')\n",
    "        self.colormap_range_slider.param.watch(self._colormap_callback, 'value')\n",
    "        \n",
    "    def _colormap_callback(self, *events):\n",
    "        event = events[0]\n",
    "        if event.obj == self.colormap_min:\n",
    "            # The colormap value has been changed.\n",
    "            # We need to potentially update the colormap range slider min value\n",
    "            # We need to potentially update the colormap_range_slider values\n",
    "            new_value = int(event.new)\n",
    "            if self.colormap_range_slider.start > new_value:\n",
    "                self.colormap_range_slider.start = new_value\n",
    "            \n",
    "            vals = list(self.colormap_range_slider.value)\n",
    "            if vals[0] != new_value:\n",
    "                vals[0] = new_value\n",
    "                self.colormap_range_slider.value = tuple(vals)\n",
    "            \n",
    "            # Have we manually changed the minimum value?\n",
    "            min_value = int(self.ds[self.attribute.value].min())\n",
    "\n",
    "            if new_value == min_value:\n",
    "                # The new value is the minimum value so we want the min values to\n",
    "                # update automatically\n",
    "                self._auto_update_cmap_min = True\n",
    "            else:\n",
    "                self._auto_update_cmap_min = False\n",
    "                 \n",
    "        elif event.obj == self.colormap_max:\n",
    "            # The colormap value has been changed.\n",
    "            # We need to potentially update the colormap range slider max value\n",
    "            # We need to potentially update the colormap_range_slider values\n",
    "            new_value = int(event.new)\n",
    "            if self.colormap_range_slider.end < new_value:\n",
    "                self.colormap_range_slider.end = new_value\n",
    "                \n",
    "            vals = list(self.colormap_range_slider.value)\n",
    "            if vals[1] != new_value:\n",
    "                vals[1] = new_value\n",
    "                self.colormap_range_slider.value = tuple(vals)\n",
    "            \n",
    "            # Have we manually changed the max value?\n",
    "            max_value = int(self.ds[self.attribute.value].max())\n",
    "            if new_value == max_value:\n",
    "                self._auto_update_cmap_max = True\n",
    "            else:\n",
    "                self._auto_update_cmap_max = False\n",
    "                \n",
    "        elif event.obj == self.colormap_range_slider:\n",
    "            # Lets see whcih values have changed\n",
    "            new_vals = event.new\n",
    "            old_vals = event.old\n",
    "            \n",
    "            # Minimum value has changed\n",
    "            if new_vals[0] != old_vals[0]:\n",
    "                self.colormap_min.value = int(new_vals[0])\n",
    "            # Maximum value has changed\n",
    "            if new_vals[1] != old_vals[1]:\n",
    "                self.colormap_max.value = int(new_vals[1])\n",
    "        \n",
    "    @pn.depends(\"file.value\", watch=True)\n",
    "    def _parse_file_input(self):\n",
    "        self.loaded = False\n",
    "        value = self.file.value\n",
    "        # We are dealing with a h5netcdf file ->\n",
    "        # The reader can't read bytes so we need to write it to a file like object\n",
    "        if value.startswith(b\"\\211HDF\\r\\n\\032\\n\"):\n",
    "            value = io.BytesIO(value)\n",
    "        ds = xr.open_dataset(value)\n",
    "        self.curvilinear_coordinates = None\n",
    "        \n",
    "        number_coordinates_in_system = len(list(ds.coords.variables.values())[0].dims)\n",
    "        # Standard Grid\n",
    "        if number_coordinates_in_system == 1:\n",
    "            pass\n",
    "        # Curvilinear coordinates\n",
    "        elif number_coordinates_in_system == 2:\n",
    "            dims = list(ds[list(ds.coords)[0]].dims)\n",
    "            # Store the true coordinates for export\n",
    "            self.curvilinear_coordinates = list(ds.coords)\n",
    "            # Add the dimension into the coordinates this results in an ij indexing\n",
    "            ds.coords[dims[0]] = ds[dims[0]]\n",
    "            ds.coords[dims[1]] = ds[dims[1]]\n",
    "            # Remove the curvilinear coordinates from the original coordinates\n",
    "            ds = ds.reset_coords()\n",
    "        else:\n",
    "            raise ValueError(\"Unknown number of Coordinates\")\n",
    "        self.ds = ds\n",
    "        self.attribute.options = list(ds.keys())\n",
    "        self._original_ds = ds.copy(deep=True)\n",
    "        self.loaded = True\n",
    "        return True\n",
    "        \n",
    "    def _set_values(self, value, calculation_type, selection_expr):\n",
    "        hvds = hv.Dataset(self.ds.to_dataframe(dim_order=[*list(self.ds[self.attribute.value].dims)]).reset_index())\n",
    "        if calculation_type == 'Absolute':\n",
    "            hvds.data[self.attribute.value].loc[hvds.select(selection_expr).data.index] = value\n",
    "        elif calculation_type == 'Relative':\n",
    "            hvds.data[self.attribute.value].loc[hvds.select(selection_expr).data.index] += value\n",
    "        elif calculation_type == 'Percentage':\n",
    "            hvds.data[self.attribute.value].loc[hvds.select(selection_expr).data.index] *=  (100 + value) / 100.\n",
    "        self.ds[self.attribute.value] = list(self.ds[self.attribute.value].dims), hvds.data[self.attribute.value].values.reshape(*self.ds[self.attribute.value].shape)\n",
    "        ds = self.ds.copy(deep=True)\n",
    "        self.ds = ds\n",
    "        \n",
    "    def _download_netcdf(self):\n",
    "        filename, extension = os.path.splitext(self.file.filename) \n",
    "        self.download_netcdf.filename = filename + \"_netcdf-editor\" + extension\n",
    "        ds = self.ds\n",
    "        # We need to remove the dimension coordinates and reset the curvilinear coordinates\n",
    "        if self.curvilinear_coordinates is not None:\n",
    "            ds = self.ds.drop([*self.ds.dims]).set_coords([*self.curvilinear_coordinates])\n",
    "        return io.BytesIO(ds.to_netcdf())\n",
    "    \n",
    "    def _download_script(self):\n",
    "        from inspect import getsource\n",
    "        file_contents = ''\n",
    "        \n",
    "        file_contents += \"\\n\".join([\n",
    "            'import holoviews as hv',\n",
    "            'from holoviews.util.transform import dim',\n",
    "            'import numpy',\n",
    "            'import xarray as xr',\n",
    "            'from skimage.morphology import reconstruction',\n",
    "            'import argparse', # Get info off from the command line\n",
    "            'import os', # Used to modify file name\n",
    "            'from unittest.mock import Mock', # We use unittest.Mock to mock the attribute spinner class which we will get from command line\n",
    "        ])\n",
    "        \n",
    "        file_contents += '\\n\\n'\n",
    "        \n",
    "        lines = [\n",
    "            \"class ValueChanger(object):\",\n",
    "            \"\\n\",\n",
    "            \"    \" + \"def __init__(self, ds, attribute):\",\n",
    "            \"    \" * 2 + \"self.ds = ds\",\n",
    "            \"    \" * 2 + \"self.attribute = attribute\",\n",
    "        ]\n",
    "        \n",
    "        file_contents += \"\\n\".join(lines) + \"\\n\\n\"\n",
    "        \n",
    "        output_functions = [\n",
    "            self._apply_action,\n",
    "            self._set_values,\n",
    "            self._fill_depressions,\n",
    "        ]\n",
    "        \n",
    "        # Get all the functions needed to rerun\n",
    "        # The scripts and tidy them up\n",
    "        for func in output_functions:\n",
    "            source = getsource(func)\n",
    "            \n",
    "            # Remove all references to self\n",
    "#             for word in ['self,', 'self.', 'self']:\n",
    "#                 source = source.replace(word, \"\")\n",
    "            \n",
    "#             # Tab instead of whitespaces\n",
    "#             source = source.replace(\"    \", \"\\t\")\n",
    "            \n",
    "#             # Remove extra tabs at start of line because \n",
    "#             # The functions were in a class\n",
    "#             source = \"\\n\".join([\n",
    "#                 line[1:] # remove first tab\n",
    "#                     for line in source.split(\"\\n\")\n",
    "#             ])\n",
    "            \n",
    "            file_contents += source + \"\\n\"\n",
    "        \n",
    "        # Import the data\n",
    "        lines = [\n",
    "            \"print('Reading command line arguments in')\",\n",
    "            'parser = argparse.ArgumentParser()',\n",
    "            'parser.add_argument(\"--file\", \"-f\", type=str, required=True)',\n",
    "            'parser.add_argument(\"--attribute\", \"-a\", type=str, required=True)',\n",
    "            'args = parser.parse_args()',\n",
    "            '\\n',\n",
    "            'print(\"Opening dataset\")',\n",
    "            'ds = xr.open_dataset(args.file)',\n",
    "            'attribute = Mock(value = args.attribute)'\n",
    "            '\\n',\n",
    "            'print(\"Creating Class\")',\n",
    "            'vc = ValueChanger(ds, attribute)',\n",
    "        ]\n",
    "        \n",
    "        file_contents += \"\\n\".join(lines) + '\\n'\n",
    "        \n",
    "        # Add all the actions to the file\n",
    "        \n",
    "        actions_string = str(self._undo_list)\n",
    "        actions_string = actions_string.replace(\n",
    "            \"{\", \"\\n    {\").replace(    # Each dictionnary starts on a newline\n",
    "            \", \", \",\\n    \").replace(    # Each dictionnary entry starts on a new line\n",
    "            \"}]\", \"}\\n]\")            # final bracket separation to end list on newline\n",
    "        \n",
    "        file_contents += \"print('Reading in actions')\"\n",
    "        file_contents += '\\nactions = '\n",
    "        file_contents += actions_string\n",
    "            \n",
    "        file_contents += \"\\n\\n\"\n",
    "        \n",
    "        lines = [\n",
    "            \"print('Applying actions')\",\n",
    "            \"for action in actions:\",\n",
    "            \"    \" + \"vc._apply_action(action)\",\n",
    "            'filename, extension = os.path.splitext(args.file)',\n",
    "            \"new_filename = filename + '_script_auto_generated' + extension\",\n",
    "            \"print(f'writing to new file: {new_filename}')\",\n",
    "            \"vc.ds.to_netcdf(new_filename)\",\n",
    "            \"print('done')\",\n",
    "        ]\n",
    "        \n",
    "        file_contents += \"\\n\".join(lines)\n",
    "        \n",
    "        return io.StringIO(file_contents)\n",
    "            \n",
    "    def undo(self, event):\n",
    "        # Nothing in the undo list\n",
    "        if not len(self._undo_list):\n",
    "            return \n",
    "        \n",
    "        # Get the last action in the undo list\n",
    "        undo_action = self._undo_list.pop()\n",
    "        self._redo_list.append(undo_action.copy())\n",
    "        \n",
    "        # If it is 'Absolute' Change we don't stock the\n",
    "        # initial values so we have to run all the steps up to this one to \n",
    "        # undo this change\n",
    "        if undo_action['calculation_type'] in ['Absolute', 'Depression_filling'] :\n",
    "            # We reset the dataset to it's initial value\n",
    "            self.ds = self._original_ds.copy(deep=True)\n",
    "            # We apply each step one by one\n",
    "            for action in self._undo_list:\n",
    "                self._apply_action(action)\n",
    "\n",
    "        elif undo_action['calculation_type'] == 'Relative' :\n",
    "            # Apply the opposite transformation\n",
    "            undo_action['value'] *= -1\n",
    "            self._apply_action(undo_action)\n",
    "        elif undo_action['calculation_type'] == 'Percentage' :\n",
    "            # Apply the opposite transformation\n",
    "            undo_action['value'] = ((100 * 100) / (100 + undo_action['value'])) - 100\n",
    "            self._apply_action(undo_action)\n",
    "        else:\n",
    "            raise ValueError(\"Can not undo action, unknown calculation type {}\".format(undo_action['calculation_type']))\n",
    "            \n",
    "    def redo(self, event):\n",
    "        # Nothing in the redo list\n",
    "        if not len(self._redo_list):\n",
    "            return \n",
    "        \n",
    "        # Get the last action in the redo list\n",
    "        redo_action = self._redo_list.pop()\n",
    "        \n",
    "        self._apply_action(redo_action)\n",
    "        # Add the action to the list of undo actions\n",
    "        self._undo_list.append(redo_action)\n",
    "            \n",
    "    def _apply_action(self, action):\n",
    "        if action['calculation_type'] in ['Absolute', 'Percentage', 'Relative']:\n",
    "            self._set_values(\n",
    "                value = action['value'], \n",
    "                calculation_type = action['calculation_type'],\n",
    "                selection_expr = action['selection_expr']\n",
    "            )\n",
    "        elif action['calculation_type'] == 'Depression_filling':\n",
    "            self._fill_depressions()\n",
    "        else:\n",
    "            raise ValueError(\"Cannot apply step {}, unknown calculation_type {}\". format(action, action['calculation_step']))\n",
    "    \n",
    "    def _apply_values(self, event):\n",
    "        if self.selection.selection_expr is None:\n",
    "            return\n",
    "        action = {\n",
    "            'selection_expr': self.selection.selection_expr,\n",
    "            'calculation_type': self.calculation_type.value,\n",
    "            'value': self.spinner.value\n",
    "        }\n",
    "        # Apply the action\n",
    "        self._apply_action(action)\n",
    "        \n",
    "        # Add the action to the list of undo actions\n",
    "        self._undo_list.append(action)\n",
    "        \n",
    "        self.selection.selection_expr = None\n",
    "        \n",
    "    def _fill_depressions_callback(self, event):\n",
    "        # Add it to the undo list\n",
    "        action = {\n",
    "            'selection_expr': None,\n",
    "            'calculation_type': 'Depression_filling',\n",
    "            'value': None,\n",
    "        }\n",
    "        self._undo_list.append(action)\n",
    "        self._apply_action(action)\n",
    "        \n",
    "    def _fill_depressions(self):\n",
    "        dem = self.ds[self.attribute.value].values\n",
    "        seed = numpy.copy(dem)\n",
    "        seed[1:-1, 1:-1] = dem.max()\n",
    "\n",
    "        filled = reconstruction(seed, dem, method='erosion')\n",
    "        filled[dem <= 0] = dem[dem <= 0]\n",
    "        self.ds[self.attribute.value] = list(self.ds[self.attribute.value].dims), filled\n",
    "        ds = self.ds.copy(deep=True)\n",
    "        self.ds = ds\n",
    "        \n",
    "    def _get_ordered_coordinate_dimension_names(self):\n",
    "        dimension_names = list(self.ds.coords)\n",
    "        if 'lat' in dimension_names[0].lower() and 'lon' in dimension_names[1].lower():\n",
    "            dimension_names = dimension_names[::-1]\n",
    "        elif 'x' == dimension_names[1].lower() or 'y' == dimension_names[0].lower():\n",
    "            dimension_names = dimension_names[::-1]\n",
    "        return dimension_names\n",
    "            \n",
    "    def _calculate_internal_oceans(self):\n",
    "        # Calculate a binary array of above and below see level\n",
    "        # from scipy doc:  Any non-zero values in `input` are\n",
    "        # counted as features and zero values are considered the background.\n",
    "        # This is why we choose ocean = True\n",
    "        ocean = self.ds[self.attribute.value] <= 0\n",
    "        \n",
    "        # Use scipy to calculate internal oceans\n",
    "        labeled_array, num_features = measurements.label(ocean)\n",
    "        \n",
    "        # Replace continents with numpy.NaN\n",
    "        # Originally they are ints or floats and numpy.NaN can't be set\n",
    "        labeled_array = labeled_array.astype(object)\n",
    "        # continents have a value of 0\n",
    "        labeled_array[labeled_array==0] = numpy.NaN\n",
    "        \n",
    "        return labeled_array\n",
    "    \n",
    "    def _calculate_passage_problems(self):\n",
    "        # Define template we are looking for passages\n",
    "        # Where only diffusion occurs this means we are looking\n",
    "        # for ocean passages one in width/height\n",
    "        # 1 => Ocean\n",
    "        # -1 => Land\n",
    "        # 0 = Indifferent\n",
    "        template = numpy.array([[0, 1, 0], \n",
    "                                [-1,1,-1], \n",
    "                                [0, 1, 0]])\n",
    "\n",
    "        # Theoretical max value when the template is found\n",
    "        # Note that 0s are considered wildcards so they are not taken into\n",
    "        # Account \n",
    "        #TODO this only works on data arrays where the absolute values are 1\n",
    "        perfect_match = numpy.sum(numpy.abs(template))\n",
    "\n",
    "        # we recode the values of land to -1 as\n",
    "        # we did in the template\n",
    "        values = (self.ds[self.attribute.value].values <= 0).astype(int)\n",
    "        values[values == 0] = -1\n",
    "\n",
    "        # Create an empty array where we are going to stock the values\n",
    "        #TODO This could potentially by a binary array??\n",
    "        potential_points = values\n",
    "#         potential_points[:] = numpy.nan\n",
    "\n",
    "        # Mark points where there is only diffusion in longitude direction\n",
    "        convolvedh = convolve2d(values, template, 'same')\n",
    "        potential_points[convolvedh == perfect_match] = 2\n",
    "\n",
    "        # Mark points where there is only diffusion in latitude direction\n",
    "        convolvedv = convolve2d(values, template.T, 'same')\n",
    "        potential_points[convolvedv == perfect_match] = 2\n",
    "        \n",
    "        potential_points = potential_points.astype(object)\n",
    "        potential_points[potential_points == -1] = numpy.NaN\n",
    "        \n",
    "        return potential_points\n",
    "        \n",
    "    @pn.depends(\"file.filename\", watch=True)\n",
    "    def _toggle_options_pane(self):\n",
    "        self.options_pane.clear()\n",
    "        if self.file.filename is not None:\n",
    "            self.options_pane.extend([\n",
    "                pn.pane.Markdown('''### Variable'''),\n",
    "                pn.Column(self.attribute),\n",
    "                pn.pane.Markdown('''### Colormaps'''),\n",
    "                pn.Column(self.colormap, pn.Column(pn.Row(self.colormap_min, pn.layout.HSpacer(), self.colormap_max), self.colormap_range_slider), self.colormap_delta),\n",
    "                pn.pane.Markdown('''### Mask'''),\n",
    "                pn.Row(self.mask, self.mask_value), \n",
    "                pn.pane.Markdown('''### Extra Maps'''),\n",
    "                pn.Column(self.show_internal_oceans, self.show_passage_problems),\n",
    "                pn.pane.Markdown('''### Change Values'''),\n",
    "                pn.Column(self.calculation_type, self.spinner, self.apply, self.fill_depressions_button, pn.Row(self.undo_button, self.redo_button)), \n",
    "                pn.Column(self.download_netcdf, self.download_script),\n",
    "            ])\n",
    "            \n",
    "    def get_grid_style(self):\n",
    "        # Calculate Ticks\n",
    "        ydim, xdim = self.ds[self.attribute.value].dims\n",
    "        xvals = self.ds[xdim].values\n",
    "        yvals = self.ds[ydim].values\n",
    "        x_ticks = (xvals[1:] + xvals[:-1]) / 2\n",
    "        y_ticks = (yvals[1:] + yvals[:-1]) / 2\n",
    "        # Setup a grid style\n",
    "        grid_style = {\n",
    "            'grid_line_color': 'black', 'grid_line_width': 1,\n",
    "            'xgrid_ticker': x_ticks, 'ygrid_ticker': y_ticks\n",
    "        }\n",
    "        return grid_style\n",
    "            \n",
    "    def _update_clims(self):\n",
    "        min_value = int(self.ds[self.attribute.value].min())\n",
    "        max_value = int(self.ds[self.attribute.value].max())\n",
    "        # Update the limits of the range slider witht the new values\n",
    "        self.colormap_range_slider.start = min_value\n",
    "        self.colormap_range_slider.end = max_value\n",
    "        # Don't necessarily update the min / max values of the colormap\n",
    "        if self._auto_update_cmap_min:\n",
    "            self.colormap_min.value = min_value\n",
    "        if self._auto_update_cmap_max:\n",
    "            self.colormap_max.value = max_value\n",
    "    \n",
    "    def _clims(self):\n",
    "        if self.mask.value:\n",
    "            return self.mask_value.value, self.mask_value.value\n",
    "        else:\n",
    "            return self.colormap_min.value, self.colormap_max.value\n",
    "\n",
    "    def _color_levels(self):\n",
    "        if self.colormap_delta.value <= 0:\n",
    "            return None\n",
    "        return list(range(self.colormap_min.value, self.colormap_max.value, self.colormap_delta.value)) + [self.colormap_max.value]\n",
    "            \n",
    "    def _colorbar_opts(self):\n",
    "        if self.colormap_delta.value <= 0:\n",
    "            return {}\n",
    "        ticks = self._color_levels()\n",
    "        if len(ticks) > 8:\n",
    "            ticks = ticks[::len(ticks)//8] + [ticks[-1]]\n",
    "        # Add 0 to the ticks\n",
    "        if self.colormap_min.value * self.colormap_max.value < 0: # Either side of 0\n",
    "            ticks = numpy.insert(ticks, numpy.searchsorted(ticks, 0), 0)\n",
    "        return {'ticker': FixedTicker(ticks=ticks)}\n",
    "    \n",
    "    @pn.depends('colormap.value', 'colormap_min.value', 'colormap_max.value', 'mask.value', 'mask_value.value', 'colormap_delta.value')\n",
    "    def _opts(self, element):\n",
    "        return element.opts(\n",
    "            cmap=self.colormap.value,\n",
    "            clim=self._clims(),\n",
    "            color_levels=self._color_levels(),\n",
    "            colorbar_opts=self._colorbar_opts(),\n",
    "        )\n",
    "    \n",
    "    @pn.depends('ds', 'attribute.value')\n",
    "    def load_attribute_map(self):\n",
    "        self._update_clims()\n",
    "        return hv.Image(\n",
    "                    self.ds[self.attribute.value],\n",
    "                    [*self._get_ordered_coordinate_dimension_names()])\n",
    "    \n",
    "    @pn.depends('ds', 'attribute.value')\n",
    "    def load_passage_problems(self):\n",
    "        passage_problems = self._calculate_passage_problems()\n",
    "        number_passage_problems = numpy.sum(passage_problems[passage_problems == 2])\n",
    "        \n",
    "        # Make sure the array shapes line up\n",
    "        coordinates_shapes = tuple(self.ds.coords.dims.values())\n",
    "        if passage_problems.shape == coordinates_shapes:\n",
    "            passage_problems = xr.DataArray(passage_problems, self.ds.coords)\n",
    "        elif passage_problems.T.shape == coordinates_shapes:\n",
    "            passage_problems = xr.DataArray(passage_problems.T, self.ds.coords)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown array size of passage problem\")\n",
    "            \n",
    "        passage_problems_image = hv.Image(\n",
    "            passage_problems, \n",
    "            [*self._get_ordered_coordinate_dimension_names()], \n",
    "            group='Passage_problems', \n",
    "            label =f\"Number Diffusive Passage cells: {number_passage_problems}\"\n",
    "        )\n",
    "        return passage_problems_image\n",
    "    \n",
    "    @pn.depends('ds', 'attribute.value')\n",
    "    def load_internal_oceans(self):\n",
    "        internal_oceans = self._calculate_internal_oceans()\n",
    "        number_oceans = numpy.nanmax(internal_oceans)\n",
    "        \n",
    "        # Lets counts the number of times each ocean appears this can then be used to\n",
    "        # Filter out and find the bigger oceans\n",
    "        nbs, counts = numpy.unique(internal_oceans[~numpy.isnan(internal_oceans.astype(float))], return_counts=True)\n",
    "        \n",
    "        # Replace the biggest body of water with -1 this will show it as the default body of water\n",
    "        internal_oceans[internal_oceans == nbs[numpy.argmax(counts)]] = -1 \n",
    "        \n",
    "        # Make sure the array shapes line up\n",
    "        coordinates_shapes = tuple(self.ds.coords.dims.values())\n",
    "        if internal_oceans.shape == coordinates_shapes:\n",
    "            internal_oceans = xr.DataArray(internal_oceans, self.ds.coords)\n",
    "        elif internal_oceans.T.shape == coordinates_shapes:\n",
    "            internal_oceans = xr.DataArray(internal_oceans.T, self.ds.coords)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown array size of passage problem\")\n",
    "            \n",
    "        internal_oceans_image = hv.Image(\n",
    "            internal_oceans, \n",
    "            [*self._get_ordered_coordinate_dimension_names()],\n",
    "            group=\"Internal_Oceans\",\n",
    "            label=f'Number Internal Oceans: {number_oceans - 1}'\n",
    "        )\n",
    "        return internal_oceans_image\n",
    "\n",
    "    @pn.depends('show_internal_oceans.value',\n",
    "                'show_passage_problems.value',\n",
    "                'loaded',\n",
    "                watch=True)\n",
    "    def get_plots(self):\n",
    "        if not self.loaded:\n",
    "            return\n",
    "\n",
    "        attribute_image = hv.DynamicMap(self.load_attribute_map).apply(self._opts).opts(\n",
    "                    clipping_colors={'min': 'lightgray', 'max': 'black'},\n",
    "                    tools = ['hover']\n",
    "                )\n",
    "\n",
    "        graphs = attribute_image\n",
    "        \n",
    "        if self.show_internal_oceans.value:\n",
    "            internal_oceans = hv.DynamicMap(self.load_internal_oceans).opts(\n",
    "                hv.opts.Image('Internal_Oceans', clipping_colors = {'NaN': '#dedede', 'max': 'red', 'min': '#ffffff'}, clim=(1.2, 1.5), colorbar=False, tools=[])\n",
    "            )\n",
    "            graphs += internal_oceans\n",
    "            \n",
    "        if self.show_passage_problems.value:\n",
    "            passage_problems = hv.DynamicMap(self.load_passage_problems).opts(\n",
    "                hv.opts.Image('Passage_problems', clipping_colors = {'NaN': '#dedede', 'max': 'red', 'min': '#ffffff'}, clim=(1.2, 1.5), colorbar=False, tools=[])\n",
    "            )\n",
    "            graphs += passage_problems\n",
    "        \n",
    "        layout = self.selection(graphs + self.ds[self.attribute.value].hvplot.hist())\n",
    "        \n",
    "        layout.opts(\n",
    "            hv.opts.Histogram(tools=['hover']),\n",
    "            hv.opts.Image(\n",
    "                tools=['hover', 'box_select', 'lasso_select'], \n",
    "                show_grid=True,\n",
    "                gridstyle=self.get_grid_style(),\n",
    "                alpha = 0.75\n",
    "            )\n",
    "        ).cols(2)\n",
    "        \n",
    "        self.graph_pane.clear()\n",
    "        self.graph_pane.append(\n",
    "            layout\n",
    "        )\n",
    "        self._auto_update_cmap_min = True\n",
    "        self._auto_update_cmap_max = True\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.name\n",
    "    \n",
    "    def plot(self):\n",
    "        template = pn.template.MaterialTemplate(title='NetCDF Editor App', \n",
    "                                        logo=\"https://raw.githubusercontent.com/CEREGE-CL/CEREGE-CL.github.io/main/logo.png\", \n",
    "                                        favicon=\"https://raw.githubusercontent.com/CEREGE-CL/CEREGE-CL.github.io/main/logo.png\", \n",
    "                                        header_background = '#42a5f5', \n",
    "                                       )\n",
    "        template.sidebar.append(self.file_pane)\n",
    "        template.sidebar.append(self.options_pane)\n",
    "        template.main.append(self.graph_pane)\n",
    "        return template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = ValueChanger()\n",
    "pn.serve(vc.plot().servable('NetCDF Editor'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PANGEO)",
   "language": "python",
   "name": "pangeo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
